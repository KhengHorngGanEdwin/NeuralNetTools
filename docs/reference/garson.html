<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Variable importance using Garson's algorithm — garson • NeuralNetTools</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Variable importance using Garson's algorithm — garson" />

<meta property="og:description" content="Relative importance of input variables in neural networks using Garson's algorithm" />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">NeuralNetTools</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">1.5.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Variable importance using Garson's algorithm</h1>
    
    <div class="hidden name"><code>garson.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Relative importance of input variables in neural networks using Garson's algorithm</p>
    
    </div>

    <pre class="usage"><span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>...</span>)

<span class='co'># S3 method for default</span>
<span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>x_names</span>, <span class='no'>y_names</span>, <span class='kw'>bar_plot</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>x_lab</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>y_lab</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)

<span class='co'># S3 method for numeric</span>
<span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>struct</span>, <span class='no'>...</span>)

<span class='co'># S3 method for nnet</span>
<span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>...</span>)

<span class='co'># S3 method for mlp</span>
<span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>...</span>)

<span class='co'># S3 method for nn</span>
<span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>...</span>)

<span class='co'># S3 method for train</span>
<span class='fu'>garson</span>(<span class='no'>mod_in</span>, <span class='no'>...</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>mod_in</th>
      <td><p>input model object or a list of model weights as returned from <code><a href='neuralweights.html'>neuralweights</a></code> if using the default method</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>arguments passed to other methods</p></td>
    </tr>
    <tr>
      <th>x_names</th>
      <td><p>chr string of input variable names, obtained from the model object</p></td>
    </tr>
    <tr>
      <th>y_names</th>
      <td><p>chr string of response variable names, obtained from the model object</p></td>
    </tr>
    <tr>
      <th>bar_plot</th>
      <td><p>logical indicating if a <code>ggplot</code> object is returned (default <code>T</code>), otherwise numeric values are returned</p></td>
    </tr>
    <tr>
      <th>x_lab</th>
      <td><p>chr string of alternative names to be used for explanatory variables in the figure, default is taken from <code>mod_in</code></p></td>
    </tr>
    <tr>
      <th>y_lab</th>
      <td><p>chr string of alternative name to be used for the y-axis in the figure</p></td>
    </tr>
    <tr>
      <th>struct</th>
      <td><p>numeric vector equal in length to the number of layers in the network.  Each number indicates the number of nodes in each layer starting with the input and ending with the output.  An arbitrary number of hidden layers can be included.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A <code><a href='http://www.rdocumentation.org/packages/ggplot2/topics/ggplot'>ggplot</a></code> object for plotting if <code>bar_plot = FALSE</code>, otherwise a <code>data.frame</code> of relative importance values for each input variable.  The default aesthetics for <code><a href='http://www.rdocumentation.org/packages/ggplot2/topics/ggplot'>ggplot</a></code> can be further modified, as shown with the examples.</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>The weights that connect variables in a neural network are partially analogous to parameter coefficients in a standard regression model and can be used to describe relationships between variables. The weights dictate the relative influence of information that is processed in the network such that input variables that are not relevant in their correlation with a response variable are suppressed by the weights. The opposite effect is seen for weights assigned to explanatory variables that have strong positive or negative associations with a response variable. An obvious difference between a neural network and a regression model is that the number of weights is excessive in the former case. This characteristic is advantageous in that it makes neural networks very flexible for modeling non-linear functions with multiple interactions, although interpretation of the effects of specific variables is of course challenging.</p>
<p>A method described in Garson 1991 (also see Goh 1995) identifies the relative importance of explanatory variables for a single response variables in a supervised neural network by deconstructing the model weights. The relative importance (or strength of association) of a specific explanatory variable for the response variable can be determined by identifying all weighted connections between the nodes of interest. That is, all weights connecting the specific input node that pass through the hidden layer to the response variable are identified. This is repeated for all other explanatory variables until a list of all weights that are specific to each input variable is obtained. The connections are tallied for each input node and scaled relative to all other inputs. A single value is obtained for each explanatory variable that describes the relationship with the response variable in the model (see the appendix in Goh 1995 for a more detailed description). The original algorithm indicates relative importance as the absolute magnitude from zero to one such the direction of the response cannot be determined.</p>
<p>Misleading results may be produced if the neural network was created with a skip-layer using <code>skip = TRUE</code> with the <code><a href='http://www.rdocumentation.org/packages/nnet/topics/nnet'>nnet</a></code> or <code><a href='http://www.rdocumentation.org/packages/caret/topics/train'>train</a></code> functions.  Garson's algorithm does not describe the effects of skip layer connections on estimates of variable importance.  As such, these values are removed prior to estimating variable importance.</p>
<p>The algorithm currently only works for neural networks with one hidden layer and one response variable.</p>
    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Beck, M.W. 2018. NeuralNetTools: Visualization and Analysis Tools for Neural Networks. Journal of Statistical Software. 85(11):1-20.</p>
<p>Garson, G.D. 1991. Interpreting neural network connection weights. Artificial Intelligence Expert. 6(4):46-51.</p>
<p>Goh, A.T.C. 1995. Back-propagation neural networks for modeling complex systems. Artificial Intelligence in Engineering. 9(3):143-151.</p>
<p>Olden, J.D., Jackson, D.A. 2002. Illuminating the 'black-box': a randomization approach for understanding variable contributions in artificial neural networks. Ecological Modelling. 154:135-150.</p>
<p>Olden, J.D., Joy, M.K., Death, R.G. 2004. An accurate comparison of methods for quantifying variable importance in artificial neural networks using simulated data. Ecological Modelling. 178:389-397.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='olden.html'>olden</a></code> for a more flexible approach for variable importance</p></div>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>
<span class='co'>## using numeric input</span>

<span class='no'>wts_in</span> <span class='kw'>&lt;-</span> <span class='fu'>c</span>(<span class='fl'>13.12</span>, <span class='fl'>1.49</span>, <span class='fl'>0.16</span>, -<span class='fl'>0.11</span>, -<span class='fl'>0.19</span>, -<span class='fl'>0.16</span>, <span class='fl'>0.56</span>, -<span class='fl'>0.52</span>, <span class='fl'>0.81</span>)
<span class='no'>struct</span> <span class='kw'>&lt;-</span> <span class='fu'>c</span>(<span class='fl'>2</span>, <span class='fl'>2</span>, <span class='fl'>1</span>) <span class='co'>#two inputs, two hidden, one output </span>

<span class='fu'>garson</span>(<span class='no'>wts_in</span>, <span class='no'>struct</span>)</div><div class='img'><img src='garson-1.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'>## using nnet</span>

<span class='fu'>library</span>(<span class='no'>nnet</span>)

<span class='fu'>data</span>(<span class='no'>neuraldat</span>)
<span class='fu'>set.seed</span>(<span class='fl'>123</span>)

<span class='no'>mod</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='http://www.rdocumentation.org/packages/nnet/topics/nnet'>nnet</a></span>(<span class='no'>Y1</span> ~ <span class='no'>X1</span> + <span class='no'>X2</span> + <span class='no'>X3</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>neuraldat</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>5</span>)</div><div class='output co'>#&gt; # weights:  26
#&gt; initial  value 259.012592 
#&gt; iter  10 value 0.986480
#&gt; iter  20 value 0.225311
#&gt; iter  30 value 0.139585
#&gt; iter  40 value 0.098961
#&gt; iter  50 value 0.038200
#&gt; iter  60 value 0.022839
#&gt; iter  70 value 0.013774
#&gt; iter  80 value 0.008530
#&gt; iter  90 value 0.005172
#&gt; iter 100 value 0.003044
#&gt; final  value 0.003044 
#&gt; stopped after 100 iterations</div><div class='input'>
<span class='fu'>garson</span>(<span class='no'>mod</span>)</div><div class='img'><img src='garson-2.png' alt='' width='700' height='433' /></div><div class='input'>
</div><span class='co'># NOT RUN {</span>
<span class='co'>## using RSNNS, no bias layers</span>

<span class='fu'>library</span>(<span class='no'>RSNNS</span>)

<span class='no'>x</span> <span class='kw'>&lt;-</span> <span class='no'>neuraldat</span>[, <span class='fu'>c</span>(<span class='st'>'X1'</span>, <span class='st'>'X2'</span>, <span class='st'>'X3'</span>)]
<span class='no'>y</span> <span class='kw'>&lt;-</span> <span class='no'>neuraldat</span>[, <span class='st'>'Y1'</span>]
<span class='no'>mod</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='http://www.rdocumentation.org/packages/RSNNS/topics/mlp'>mlp</a></span>(<span class='no'>x</span>, <span class='no'>y</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>5</span>)

<span class='fu'>garson</span>(<span class='no'>mod</span>)

<span class='co'>## using neuralnet</span>

<span class='fu'>library</span>(<span class='no'>neuralnet</span>)

<span class='no'>mod</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='http://www.rdocumentation.org/packages/neuralnet/topics/neuralnet'>neuralnet</a></span>(<span class='no'>Y1</span> ~ <span class='no'>X1</span> + <span class='no'>X2</span> + <span class='no'>X3</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>neuraldat</span>, <span class='kw'>hidden</span> <span class='kw'>=</span> <span class='fl'>5</span>)

<span class='fu'>garson</span>(<span class='no'>mod</span>)

<span class='co'>## using caret</span>

<span class='fu'>library</span>(<span class='no'>caret</span>)

<span class='no'>mod</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='http://www.rdocumentation.org/packages/RSNNS/topics/train'>train</a></span>(<span class='no'>Y1</span> ~ <span class='no'>X1</span> + <span class='no'>X2</span> + <span class='no'>X3</span>, <span class='kw'>method</span> <span class='kw'>=</span> <span class='st'>'nnet'</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>neuraldat</span>, <span class='kw'>linout</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)

<span class='fu'>garson</span>(<span class='no'>mod</span>)

<span class='co'>## modify the plot using ggplot2 syntax</span>
<span class='fu'>library</span>(<span class='no'>ggplot2</span>)

<span class='no'>mod</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='http://www.rdocumentation.org/packages/nnet/topics/nnet'>nnet</a></span>(<span class='no'>Y1</span> ~ <span class='no'>X1</span> + <span class='no'>X2</span> + <span class='no'>X3</span>, <span class='kw'>data</span> <span class='kw'>=</span> <span class='no'>neuraldat</span>, <span class='kw'>size</span> <span class='kw'>=</span> <span class='fl'>5</span>)

<span class='no'>cols</span> <span class='kw'>&lt;-</span> <span class='fu'>heat.colors</span>(<span class='fl'>10</span>)
<span class='fu'>garson</span>(<span class='no'>mod</span>) +
  <span class='fu'><a href='http://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous'>scale_y_continuous</a></span>(<span class='st'>'Rel. Importance'</span>, <span class='kw'>limits</span> <span class='kw'>=</span> <span class='fu'>c</span>(-<span class='fl'>1</span>, <span class='fl'>1</span>)) +
  <span class='fu'><a href='http://www.rdocumentation.org/packages/ggplot2/topics/scale_gradient'>scale_fill_gradientn</a></span>(<span class='kw'>colours</span> <span class='kw'>=</span> <span class='no'>cols</span>) +
  <span class='fu'><a href='http://www.rdocumentation.org/packages/ggplot2/topics/scale_gradient'>scale_colour_gradientn</a></span>(<span class='kw'>colours</span> <span class='kw'>=</span> <span class='no'>cols</span>)
<span class='co'># }</span></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Marcus W. Beck.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  

  </body>
</html>

